{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preprocessing\n",
    "This notebook prepares the data for input into a neural network. Since each feature may be different orders of magnitude, this can bias the learning algorithm. Thus, it is important to perform normalization and standardization on the data. Some molecular descriptor vectors contained NaN values which needed to be set to 0 to not offset the data. Sklearn's RobustScaler was used to center and scale each feature based on percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureProcessor takes in a feature vector representing a single protein or chemical, a trained scaler,\n",
    "# & max and min\n",
    "# scaler will be pscaler or cscaler depending on protein or chemical\n",
    "# max and min will be pmax/pmin for protein and cmax/cmin for chemical\n",
    "# returns new vector with features scaled and normalized\n",
    "\n",
    "def FeatureProcessor(feature_vector, scaler, max, min):\n",
    "    new_vector = np.nan_to_num(feature_vector)\n",
    "    new_vector = new_vector.reshape(1, -1)\n",
    "    new_vector = scaler.transform(new_vector)\n",
    "    new_vector = np.nan_to_num(new_vector)\n",
    "    new_vector = (new_vector - min) / (max - min)\n",
    "    new_vector = np.nan_to_num(new_vector)\n",
    "    new_vector = (new_vector * 2) - 1\n",
    "    return new_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Protein Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenates all protein files into one proteins dataframe; saves column with IDs and removes this column from df\n",
    "# proteins is the training matrix for the scaler\n",
    "\n",
    "proteins = pd.DataFrame()\n",
    "\n",
    "for i in range(1,22):\n",
    "    pfile = pd.read_csv('PROFEAT_part_' + str(i) + '.out', sep='\\t')\n",
    "    proteins = proteins.append(pfile, ignore_index = True)\n",
    "    \n",
    "plabels = proteins[['Feature']]\n",
    "proteins = proteins.drop(['Feature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes NaN values and trains robust scaler on proteins; gets min and max of the training matrix (proteins) \n",
    "\n",
    "proteins = np.nan_to_num(proteins) \n",
    "pscaler = RobustScaler().fit(proteins)\n",
    "pmin = np.ndarray.min(proteins, axis=0)\n",
    "pmax = np.ndarray.max(proteins, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves each new protein feature vector as an npy file\n",
    "for i in range(0,len(proteins)-1):\n",
    "    np.save(plabels.iloc[i]['Feature'] + '.npy', \n",
    "            FeatureProcessor(proteins[i,:], pscaler, pmax, pmin))\n",
    "\n",
    "# error? should use proteins.iloc[[i], :]  didn't do this before but now needs this to not throw error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Chemical Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenates all chemical files into one chemicals dataframe\n",
    "\n",
    "chemicals = pd.DataFrame()\n",
    "\n",
    "for i in range(1,53):\n",
    "    cfile = pd.read_csv(str(i) + '_CIDm_MDs.tsv', sep='\\t')\n",
    "    chemicals = chemicals.append(cfile, ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259908, 1613)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemicals.shape\n",
    "# all molecules present and all features (keep first column with ID for now) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 25,000 random from chemicals to be the training matrix for the scaler\n",
    "rand_chemicals = chemicals.sample(n=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1613)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_chemicals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_chemicals = rand_chemicals.reset_index(drop=True)\n",
    "rclabels = rand_chemicals[['chemical']]\n",
    "rand_chemicals = rand_chemicals.drop(['chemical'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes NaN values and trains robust scaler on rand_chemicals; gets min and max of the training matrix (rand_chemicals) \n",
    "\n",
    "rand_chemicals = np.nan_to_num(rand_chemicals) \n",
    "cscaler = RobustScaler().fit(rand_chemicals)\n",
    "cmin = np.ndarray.min(rand_chemicals, axis=0)\n",
    "cmax = np.ndarray.max(rand_chemicals, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still need to remove ID column from original chemicals and save it separately\n",
    "clabels = chemicals[['chemical']] \n",
    "chemicals = chemicals.drop(['chemical'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# runs feature processing function on original chemicals df (all chemicals) using scaler and min/max that were trained\n",
    "# on rand_chemicals df (25,000 random chemicals) \n",
    "# saves each new chemical feature vector as an npy file\n",
    "\n",
    "for i in range(0,len(chemicals)-1):\n",
    "    np.save(clabels.iloc[i]['chemical'] + '.npy', \n",
    "            FeatureProcessor(chemicals.iloc[[0], :], cscaler, cmax, cmin))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
